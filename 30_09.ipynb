{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f1708a9-7038-460f-9210-1fa0bd33669a",
   "metadata": {},
   "source": [
    "# Un modello matematico del testo in linguaggio naturale\n",
    "\n",
    "Questo modello ci aiuterà a capire come funzionano i **LLM** (Large Language Model)\n",
    "\n",
    "I LLM sono le reti neurali alla base dell'IA generativa\n",
    "\n",
    "I LLM generano il testo mediante un processo detto **autoregressione**: quando forniamo un prompt all'IA generativa, il LLM genera la risposta **token per token**. A ogni istante della generazione della risposta, LLM prende in input tutti i token del prompt e tutti i nuovi token che ha generato fino a quel momento.\n",
    "\n",
    "I LLM ricevono un input con tanti token --> es. ChatGPT ha un enorme dizionario in Python e ogni possibile token è associato ad un numero (vede una lista di numeri)\n",
    "\n",
    "In media ci sono 0.75 token per parola\n",
    "\n",
    "Ora stanno anche sviluppando i LWM (Large World Model)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f08ad71a-985a-425d-86d6-21797a1e714d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random # Caricamento di librerie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "e0be38e3-4049-4017-8bb4-95586db102d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', '?', ' ', ' ', '.', ' ', ' ', ' ', ' ', '.', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ' ', ',', ' ', '?', ' ', '!', ' ', ' ', ' ', ' ']\n"
     ]
    }
   ],
   "source": [
    "file = open(\"./Testo_Pirandello.txt\", \"r\", encoding=\"utf-8\") # Caricamento del file\n",
    "text = file.read() # Lettura del contenuto del file\n",
    "text = text.replace(\"\\n\", \" \") # Sostituisco gli \"a capo\" con degli spazi\n",
    "text = text.replace(\"  \", \" \") # Sostituisco i doppi spazi con degli spazi singoli\n",
    "\n",
    "# I nostri token sono sempre un carattere\n",
    "l_context = 4\n",
    "markov_dict = {}\n",
    "for i, _ in enumerate(text[:-l_context]):\n",
    "    ngram = text[i:i+l_context] # Da i a i + l_context\n",
    "    if ngram in markov_dict: # Se la parola c'è già nel dizionario\n",
    "        markov_dict[ngram].append(text[i+l_context]) # Aggiunge il carattere successivo alla parola al dizionario\n",
    "    else: # Altrimenti\n",
    "        markov_dict[ngram] = [text[i+l_context]] # Aggiunge la parola e il carattere successivo alla parola al dizionario\n",
    "print(markov_dict[\"sono\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af101517-a305-424c-99ff-545c5d892d11",
   "metadata": {},
   "source": [
    "Il dizionario `markov_dict` è un modello matematico del linguaggio naturale che ora usiamo per costruire un autoregressore Markoviano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "fe409b38-cb2e-47fd-87ae-9791f7c4f13f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sei così come foga: per ripresser non s'anti, aspro ragazzi sul secondere davanti appena è la per una de\n"
     ]
    }
   ],
   "source": [
    "ngram_0 = \"sei \"\n",
    "l_phrase = 100\n",
    "phrase = ngram_0;\n",
    "if len(ngram_0) != l_context:\n",
    "    print(\"Errore 404: Parola not found\")\n",
    "else:\n",
    "    for i in range(l_phrase):\n",
    "        if ngram_0 in markov_dict:\n",
    "            next_char = random.choice(markov_dict[ngram_0])\n",
    "            phrase += next_char\n",
    "            ngram_0 = phrase[-l_context:]\n",
    "        else:\n",
    "            break\n",
    "print(phrase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f682dd9-5147-490c-bbb2-8dcbdf658801",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4402b5e-7eef-42d3-afaf-ca0850833ce3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
